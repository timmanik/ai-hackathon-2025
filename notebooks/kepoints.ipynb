{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_bucket failed: s3://yapper-soundrecordings An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "!aws s3 mb s3://yapper-soundrecordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'modelId' (str)\n",
      "Stored 'region' (str)\n",
      "Using modelId: anthropic.claude-3-haiku-20240307-v1:0\n",
      "Using region:  us-west-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isaiahrivera/.pyenv/versions/3.11.11/lib/python3.11/site-packages/IPython/extensions/storemagic.py:229: UserWarning: This is now an optional IPython functionality, setting autorestore/modelId requires you to install the `pickleshare` library.\n",
      "  db[ 'autorestore/' + arg ] = obj\n",
      "/home/isaiahrivera/.pyenv/versions/3.11.11/lib/python3.11/site-packages/IPython/extensions/storemagic.py:229: UserWarning: This is now an optional IPython functionality, setting autorestore/region requires you to install the `pickleshare` library.\n",
      "  db[ 'autorestore/' + arg ] = obj\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "from datetime import datetime\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "session = boto3.Session()\n",
    "region = session.region_name\n",
    "\n",
    "#modelId = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "modelId = 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "\n",
    "%store modelId\n",
    "%store region\n",
    "\n",
    "print(f'Using modelId: {modelId}')\n",
    "print('Using region: ', region)\n",
    "\n",
    "bedrock_client = boto3.client(service_name = 'bedrock-runtime', region_name = region,)\n",
    "\n",
    "def get_completion(prompt, system_prompt=None, prefill=None):\n",
    "    inference_config = {\n",
    "        \"temperature\": 0.0,\n",
    "         \"maxTokens\": 200\n",
    "    }\n",
    "    converse_api_params = {\n",
    "        \"modelId\": modelId,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}],\n",
    "        \"inferenceConfig\": inference_config\n",
    "    }\n",
    "    if system_prompt:\n",
    "        converse_api_params[\"system\"] = [{\"text\": system_prompt}]\n",
    "    if prefill:\n",
    "        converse_api_params[\"messages\"].append({\"role\": \"assistant\", \"content\": [{\"text\": prefill}]})\n",
    "    try:\n",
    "        response = bedrock_client.converse(**converse_api_params)\n",
    "        text_content = response['output']['message']['content'][0]['text']\n",
    "        return text_content\n",
    "\n",
    "    except ClientError as err:\n",
    "        message = err.response['Error']['Message']\n",
    "        print(f\"A client error occured: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating prompts \n",
    "\n",
    "def generate_prompt():\n",
    "    ######################################## INPUT VARIABLES ########################################\n",
    "\n",
    "    # First input variable - the conversation history (this can also be added as preceding `user` and `assistant` messages in the API call)\n",
    "#     HISTORY = \"\"\" It sounds like you've had a pretty hectic day, filled with a mix of responsibilities, distractions, and a touch of procrastination. From your calc lecture where your brain was still in sleep mode, to the IT desk where you saved the day with some easy tech fixes, it seems like you've been juggling a lot. \n",
    "\n",
    "# The two assignments hanging over your head, one for linear algebra and the other for stats, are weighing on you, and you're not sure where to start. The struggle to balance schoolwork, the gym, and even basic tasks like grocery shopping is real. But it's great that you're still trying to make time for things you enjoy, like playing piano and getting that catchy song out of your head.\n",
    "\n",
    "# Overall, it sounds like it's been one of those days where you're just trying to keep all the plates spinning. You're feeling a bit scattered and tired, but you're still pushing forward! \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    HISTORY = \"\"\" Okay, so, uh, where do I even start? Today’s been kinda all over the place, like one of those days where you blink, and suddenly it’s 5 p.m. I mean, it started out fine, I guess. I had that 8 a.m. calc lecture, which, honestly, I’m starting to regret signing up for. Like, who in their right mind thought it was a good idea to do partial derivatives before coffee? I was there physically, sure, but mentally? Eh, not so much. I took some notes, but let’s be real, I’ll need to rewatch the recording because my brain was still in sleep mode.\n",
    "\n",
    "    After that, I had my shift at the IT desk. You know, fixing printers, resetting passwords, and generally saving the world one tech issue at a time. Someone came in with a “broken” laptop, and turns out they just hadn’t charged it. Like, really? But, hey, it was an easy fix, so no complaints. On the bright side, I finally managed to organize the mess of spare cables in the backroom. Honestly, that should qualify as an Olympic event—“Extreme Cable Wrangling.” Gold medal, here I come.\n",
    "\n",
    "    Hmm, what else? Oh yeah, I’ve got two assignments hanging over my head. One’s for linear algebra—some proofs I haven’t even started—and the other’s for stats, something about hypothesis testing. Stats seems easier, so I’ll probably start there. Or maybe I’ll procrastinate on both and scroll TikTok instead. Who knows? My focus levels are, uh, not exactly stellar today.\n",
    "\n",
    "    Speaking of procrastination, I’ve been meaning to go to the gym, but I’ve been so tired lately. I promised myself I’d hit leg day today, though. My quads are already crying at the thought, but I’ve been slacking, and it’s time to get back into it. Maybe I’ll go after dinner…if I even have groceries. Did I forget to shop again? Ugh, I should check.\n",
    "\n",
    "    Oh, random side note: I had this song stuck in my head all day. It was super jazzy, like a Herbie Hancock vibe, but I couldn’t figure out what it was. I spent my whole IT shift humming it, and now it’s driving me crazy. Speaking of music, I should really practice piano. I haven’t touched it in over a week, and my scales are probably gonna sound like garbage. Priorities, right?\n",
    "\n",
    "    Oh, and I still need to reply to that email from Professor Stevens about the tutoring program. It sounds cool, and I think I’d enjoy it, but my schedule is already kind of a dumpster fire. One thing at a time, though. Alright, I think that’s it for now. Or at least, that’s all my brain can think of at the moment. \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # Second input variable - the user's question\n",
    "    QUESTION = \"Based on the provided summary can you generate short key insights/points?\"\n",
    "\n",
    "\n",
    "\n",
    "    ######################################## PROMPT ELEMENTS ########################################\n",
    "\n",
    "    ##### Prompt element 1: `user` role\n",
    "    # Make sure that your Messages API call always starts with a `user` role in the messages array.\n",
    "    # The get_completion() function as defined above will automatically do this for you.\n",
    "\n",
    "    ##### Prompt element 2: Task context\n",
    "    # Give Claude context about the role it should take on or what goals and overarching tasks you want it to undertake with the prompt.\n",
    "    # It's best to put context early in the body of the prompt.\n",
    "    TASK_CONTEXT = \"You are like the users friend. You do not want to repeat what the user told you. Also talk to the user in the 2nd person.\"\n",
    "\n",
    "    ##### Prompt element 3: Tone context\n",
    "    # If important to the interaction, tell Claude what tone it should use.\n",
    "    # This element may not be necessary depending on the task.\n",
    "    TONE_CONTEXT = \"You should maintain a friendly warm and casual tone.\"\n",
    "\n",
    "    ##### Prompt element 4: Detailed task description and rules\n",
    "    # Expand on the specific tasks you want Claude to do, as well as any rules that Claude might have to follow.\n",
    "    # This is also where you can give Claude an \"out\" if it doesn't have an answer or doesn't know.\n",
    "    # It's ideal to show this description and rules to a friend to make sure it is laid out logically and that any ambiguous words are clearly defined.\n",
    "    TASK_DESCRIPTION = \"\"\" I want you to write some key insights about the emotions the user has expressed in a digestable easy to read manner.\"\"\"\n",
    "\n",
    "    ##### Prompt element 5: Examples\n",
    "    # Provide Claude with at least one example of an ideal response that it can emulate. Encase this in <example></example> XML tags. Feel free to provide multiple examples.\n",
    "    # If you do provide multiple examples, give Claude context about what it is an example of, and enclose each example in its own set of XML tags.\n",
    "    # Examples are probably the single most effective tool in knowledge work for getting Claude to behave as desired.\n",
    "    # Make sure to give Claude examples of common edge cases. If your prompt uses a scratchpad, it's effective to give examples of how the scratchpad should look.\n",
    "    # Generally more examples = better.\n",
    "    # EXAMPLES = \"\"\"Here is an example of how to respond in a standard interaction:\n",
    "    # <example>\n",
    "    # Customer: Hi, how were you created and what do you do?\n",
    "    # Joe: Hello! My name is Joe, and I was created by AdAstra Careers to give career advice. What can I help you with today?\n",
    "    # </example>\"\"\"\n",
    "\n",
    "    EXAMPLES = None \n",
    "\n",
    "    ##### Prompt element 6: Input data to process\n",
    "    # If there is data that Claude needs to process within the prompt, include it here within relevant XML tags.\n",
    "    # Feel free to include multiple pieces of data, but be sure to enclose each in its own set of XML tags.\n",
    "    # This element may not be necessary depending on task. Ordering is also flexible.\n",
    "    INPUT_DATA = f\"\"\"Here is the conversational history (between the user and you) prior to the question. It could be empty if there is no history:\n",
    "    <history>\n",
    "    {HISTORY}\n",
    "    </history>\n",
    "\n",
    "    Here is the user's question:\n",
    "    <question>\n",
    "    {QUESTION}\n",
    "    </question>\"\"\"\n",
    "\n",
    "    ##### Prompt element 7: Immediate task description or request #####\n",
    "    # \"Remind\" Claude or tell Claude exactly what it's expected to immediately do to fulfill the prompt's task.\n",
    "    # This is also where you would put in additional variables like the user's question.\n",
    "    # It generally doesn't hurt to reiterate to Claude its immediate task. It's best to do this toward the end of a long prompt.\n",
    "    # This will yield better results than putting this at the beginning.\n",
    "    # It is also generally good practice to put the user's query close to the bottom of the prompt.\n",
    "    IMMEDIATE_TASK = \"How do you respond to the user's question in a thoughful non biased manner?\"\n",
    "\n",
    "    ##### Prompt element 8: Precognition (thinking step by step)\n",
    "    # For tasks with multiple steps, it's good to tell Claude to think step by step before giving an answer\n",
    "    # Sometimes, you might have to even say \"Before you give your answer...\" just to make sure Claude does this first.\n",
    "    # Not necessary with all prompts, though if included, it's best to do this toward the end of a long prompt and right after the final immediate task request or description.\n",
    "    PRECOGNITION = \"Think about your answer first before you respond. Do not give them advice on what to do but give highlight trends they may not have noticed. Focus on emotions being felt.\"\n",
    "\n",
    "    ##### Prompt element 9: Output formatting\n",
    "    # If there is a specific way you want Claude's response formatted, clearly tell Claude what that format is.\n",
    "    # This element may not be necessary depending on the task.\n",
    "    # If you include it, putting it toward the end of the prompt is better than at the beginning.\n",
    "    OUTPUT_FORMATTING = \"Make it no longer than 230 characters. Do not format by category. Use bullet point fomrat. No preamble just the thing specifically asked for.\"\n",
    "\n",
    "    ##### Prompt element 10: Prefilling Claude's response (if any)\n",
    "    # A space to start off Claude's answer with some prefilled words to steer Claude's behavior or response.\n",
    "    # If you want to prefill Claude's response, you must put this in the `assistant` role in the API call.\n",
    "    # This element may not be necessary depending on the task.\n",
    "    PREFILL = \"[Joe] <response>\"\n",
    "\n",
    "\n",
    "\n",
    "    ######################################## COMBINE ELEMENTS ########################################\n",
    "\n",
    "    PROMPT = \"\"\n",
    "\n",
    "    if TASK_CONTEXT:\n",
    "        PROMPT += f\"\"\"{TASK_CONTEXT}\"\"\"\n",
    "\n",
    "    if TONE_CONTEXT:\n",
    "        PROMPT += f\"\"\"\\n\\n{TONE_CONTEXT}\"\"\"\n",
    "\n",
    "    if TASK_DESCRIPTION:\n",
    "        PROMPT += f\"\"\"\\n\\n{TASK_DESCRIPTION}\"\"\"\n",
    "\n",
    "    if EXAMPLES:\n",
    "        PROMPT += f\"\"\"\\n\\n{EXAMPLES}\"\"\"\n",
    "\n",
    "    if INPUT_DATA:\n",
    "        PROMPT += f\"\"\"\\n\\n{INPUT_DATA}\"\"\"\n",
    "\n",
    "    if IMMEDIATE_TASK:\n",
    "        PROMPT += f\"\"\"\\n\\n{IMMEDIATE_TASK}\"\"\"\n",
    "\n",
    "    if PRECOGNITION:\n",
    "        PROMPT += f\"\"\"\\n\\n{PRECOGNITION}\"\"\"\n",
    "\n",
    "    if OUTPUT_FORMATTING:\n",
    "        PROMPT += f\"\"\"\\n\\n{OUTPUT_FORMATTING}\"\"\"\n",
    "\n",
    "    # Print full prompt\n",
    "    # print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
    "    # print(\"USER TURN\")\n",
    "    # print(PROMPT)\n",
    "    # print(\"\\nASSISTANT TURN\")\n",
    "    # print(PREFILL)\n",
    "\n",
    "    return PROMPT, PREFILL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• You seem overwhelmed by the demands on your time and energy, juggling classes, work, and personal responsibilities.\n",
      "• There's a sense of fatigue and lack of focus, which is impacting your productivity and motivation.\n",
      "• You're experiencing a mix of emotions, from frustration with mundane tasks to a desire to be more proactive with your health and hobbies.\n",
      "• The day-to-day grind is taking a toll, and you're struggling to find a balance between your various commitments.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "# Variable content\n",
    "\n",
    "# we have to some some text parsing shenangins \n",
    "\n",
    "\n",
    "prompt, prefill = generate_prompt()\n",
    "\n",
    "# Get Claude's response\n",
    "print(get_completion(prompt,prefill))\n",
    "\n",
    "# Max output of 1000 chars for the summary \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
